{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Valent0296/allvent.github.io/blob/master/Test_4_tesi_ResNet_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN3aXnBioU2o",
        "outputId": "7e5916c6-6749-4fac-fff2-aae89dfa6f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-2.34.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.15.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (24.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.32.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (24.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.7.4)\n",
            "Downloading ray-2.34.0-cp310-cp310-manylinux2014_x86_64.whl (64.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ray\n",
            "Successfully installed ray-2.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNpVkeZy79d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "b810ef63-4909-442d-b9fa-62611eb53968"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'models' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-50e33db5da07>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#print(model_ft)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#mod=model_ft.features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial\n",
        "import os\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "#print(model_ft)\n",
        "#mod=model_ft.features\n",
        "model_ft.add_module(\"conv1\", nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)))\n",
        "model_ft.add_module(\"fc\", nn.Linear(in_features=512, out_features=512, bias=True))\n",
        "for idx, name in enumerate(model_ft.modules()):\n",
        "  if name != \"conv1\":\n",
        "    name.requires_grad_=False\n",
        "\n",
        "  if name != \"fc\":\n",
        "    name.requires_grad_=False\n",
        "\n",
        "#print(model_ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYH4tKyo967b"
      },
      "outputs": [],
      "source": [
        "#######################\n",
        "# Positional Encoding #\n",
        "#######################\n",
        "#1st version trial, future implementations will try diverse function\n",
        "class PositionalEncoding( nn.Module ):\n",
        "\n",
        "  def __init__( self, d_model: int, dropout: float=0.1, maxlen: int=8 ):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    den = torch.exp( torch.arange( 0, d_model, 2 ) * ( -math.log(10000) / d_model ) )\n",
        "    pos = torch.arange(0, maxlen).reshape( maxlen, 1 )\n",
        "    self.pe = torch.zeros( (maxlen, d_model) )\n",
        "    self.pe[:, 0::2] = torch.sin(pos*den)\n",
        "    self.pe[:, 1::2] = torch.cos(pos*den)\n",
        "    self.pe.unsqueeze_(-2) #BE CAREFUL TO THIS ONE SINCE IT CHANGES DIMENSION\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\"pos_enc\", self.pe)\n",
        "\n",
        "  def forward(self, ccn_embed: Tensor):\n",
        "    return self.dropout( ccn_embed + self.pe[ :ccn_embed.size(1), 0,: ] ) #We encode the first tok_embed.size(0) positions\n",
        "\n",
        "\n",
        "###################\n",
        "# Input embedding #\n",
        "###################\n",
        "#1st approach: try passing a CCN output as an imput embedding, (ex: 400x180)\n",
        "class SampleEmbedding( nn.Module ):\n",
        "\n",
        "  def __init__(self, d_emb: int=512):\n",
        "      super(SampleEmbedding, self).__init__()\n",
        "      self.upscale = transforms.Resize((32,32))\n",
        "      self.ccn = model_ft\n",
        "\n",
        "  def forward(self, blocks: Tensor):\n",
        "    blocks = self.upscale(blocks)\n",
        "    return self.ccn(blocks)\n",
        "\n",
        "###########\n",
        "# Masking #\n",
        "###########\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz))) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClZ_t2igvmhl"
      },
      "outputs": [],
      "source": [
        "##############\n",
        "# Tranformer #\n",
        "##############\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "  #ntokens referes to the latex vocabulary\n",
        "  def __init__(self, ntokens: int, d_mod: int, d_hid: int ,n_head: int=8, dropout: float=0.5):\n",
        "      super().__init__()\n",
        "      self.model_type = \"Transformer\"\n",
        "      self.nhead = n_head\n",
        "      self.d_model = d_mod\n",
        "      self.embedding = SampleEmbedding(d_mod)\n",
        "      self.pos_encod = PositionalEncoding(d_mod, dropout)\n",
        "      #self.tgt_encod = PositionalEncoding(10, dropout)\n",
        "      self.tgt_embed = nn.Embedding(10,d_mod)\n",
        "      encoder_layer = nn.TransformerEncoderLayer( d_mod, n_head, d_hid, batch_first=True )\n",
        "      self.transformer_encoder = nn.TransformerEncoder(encoder_layer, n_head)\n",
        "      decoder_layer = nn.TransformerDecoderLayer( d_mod, n_head, dropout=dropout, batch_first=True)\n",
        "      self.transformer_decoder = nn.TransformerDecoder(decoder_layer, n_head )\n",
        "      self.lin_soft_stack = nn.Sequential(\n",
        "          nn.Linear(d_mod, ntokens),\n",
        "          nn.Softmax(dim=1)\n",
        "      )\n",
        "      #self.init_weights()\n",
        "\n",
        "  \"\"\"def init_weights(self) -> None:\n",
        "    initrange = 0.1\n",
        "    self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "    self.lin.bias.data.zero_()\n",
        "    self.lin.weight.data.uniform_(-initrange, initrange)\"\"\"\n",
        "\n",
        "  def forward(self, src: Tensor, tgt: Tensor, tgt_mask: Tensor) -> Tensor:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "       src: Tensor, shape [seq_len, batch_size]\n",
        "\n",
        "    Returns:\n",
        "       output Tensor of shape [seq_len, batch_size, ntoken]\n",
        "    \"\"\"\n",
        "    src_emb = torch.zeros((src.size(0),src.size(1),self.d_model))\n",
        "    for i in range(src.size(1)):\n",
        "      src_emb[:,i,:] = self.embedding(src[:,i,:,:].unsqueeze(1)) * math.sqrt(self.d_model)\n",
        "    tgt = self.tgt_embed(tgt) * math.sqrt(self.d_model)\n",
        "    src_emb = self.pos_encod(src_emb)\n",
        "    tgt = self.pos_encod(tgt)\n",
        "    memory = self.transformer_encoder(src_emb)\n",
        "    deco = self.transformer_decoder(tgt, memory, tgt_mask=tgt_mask)\n",
        "    output = self.lin_soft_stack(deco)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOmh8Ntq-SNz"
      },
      "outputs": [],
      "source": [
        "model = TransformerModel(512, 512,1024)\n",
        "\"\"\"for name in model.embedding.modules():\n",
        "  print(name)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhEJaovPAZtd"
      },
      "outputs": [],
      "source": [
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = ToTensor(),\n",
        "    #target_transform= Lambda( lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1) )\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    #target_transform= Lambda( lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1) )\n",
        ")\n",
        "\n",
        "train_val_data = torch.utils.data.random_split(data, [50000, 10000], generator=torch.Generator().manual_seed(42) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsKK9aunIe9k"
      },
      "outputs": [],
      "source": [
        "#Togliere la target transform sopra\n",
        "labels_map = {\n",
        "    0: \"Zero\",\n",
        "    1: \"One\",\n",
        "    2: \"Two\",\n",
        "    3: \"Three\",\n",
        "    4: \"Four\",\n",
        "    5: \"Five\",\n",
        "    6: \"Six\",\n",
        "    7: \"Seven\",\n",
        "    8: \"Eight\",\n",
        "    9: \"Nine\",\n",
        "}\n",
        "\n",
        "figure = plt.figure(figsize=(8,8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols*rows + 1):\n",
        "  sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "  img, label = training_data[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(labels_map[label])\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48akcIKuCSC_"
      },
      "outputs": [],
      "source": [
        "\n",
        "losses_train = np.zeros((10, 10))\n",
        "losses_test = np.zeros(10)\n",
        "batches_time = np.zeros(10)\n",
        "accuracies = np.zeros((10,2))\n",
        "\n",
        "#Define train and test loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  model.train()\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "    ###FARE ATTENZIONE ALLA DIVISIBILITà DEI BATCH, PERCHè L'ULTIMO è SPESSO NON DIVISIBILE, TROVARE UN WORKAROUND\n",
        "    tgt_mask = generate_square_subsequent_mask(8)\n",
        "    #Compute prediction and loss\n",
        "    if X.size(0) == 16:\n",
        "      pred = model(X.view(2,8,28,28), y.view(2,8), tgt_mask)\n",
        "    else:\n",
        "      pred = model(X.view(8,8,28,28), y.view(8,8), tgt_mask)\n",
        "    loss = loss_fn(torch.Tensor.view(pred, (X.size(0), -1)), y)\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "   # print(\"Sono qui \", batch)\n",
        "    loss.backward()\n",
        "    #print(\"E ora qui\", batch)\n",
        "    optimizer.step()\n",
        "    correct += (torch.Tensor.view(pred, (X.size(0), -1)).argmax(1) == y).type(torch.float).sum().item()\n",
        "    if batch % 100 == 0:\n",
        "      b = (int)(batch/100)\n",
        "      losses_train[t,b]=loss.item()\n",
        "      if t == 1:\n",
        "        batches_time[b] = batch*len(X)\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"Funzione di loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "  accuracies[t][0]=100*correct/size\n",
        "\n",
        "def validation_loop(valloader, model, loss_fn, optimizer, t,checkpoint_dir=None):\n",
        "  # Validation loss\n",
        "        val_loss = 0.0\n",
        "        val_steps = 0\n",
        "        size = len(valloader.dataset)\n",
        "        correct = 0\n",
        "        for X, y in valloader:\n",
        "            with torch.no_grad():\n",
        "                tgt_mask = generate_square_subsequent_mask(8)\n",
        "                if X.size(0) == 16:\n",
        "                  pred = model(X.view(2,8,28,28), y.view(2,8), tgt_mask)\n",
        "                else:\n",
        "                  pred = model(X.view(8,8,28,28), y.view(8,8), tgt_mask)\n",
        "                val_loss += loss_fn(torch.Tensor.view(pred, (X.size(0), -1)), y).item()\n",
        "                correct += (torch.Tensor.view(pred, (X.size(0), -1)).argmax(1) == y).type(torch.float).sum().item()\n",
        "                val_steps += 1\n",
        "\n",
        "        with tune.checkpoint_dir(t) as checkpoint_dir:\n",
        "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "            torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
        "\n",
        "        tune.report(loss=(val_loss / val_steps), accuracy=correct / size)\n",
        "        print(\"Finished Validation\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "     with torch.no_grad():\n",
        "      for X, y in dataloader:\n",
        "        tgt_mask = generate_square_subsequent_mask(8)\n",
        "        if X.size(0) == 16:\n",
        "          pred = model(X.view(2,8,28,28), y.view(2,8), tgt_mask)\n",
        "        else:\n",
        "          pred = model(X.view(8,8,28,28), y.view(8,8), tgt_mask)\n",
        "        test_loss += loss_fn(torch.Tensor.view(pred, (X.size(0), -1)), y).item()\n",
        "        correct += (torch.Tensor.view(pred, (X.size(0), -1)).argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Errore test: \\n Accuratezza: {(100*correct):>0.1f}%, Media loss: {test_loss:>8f} \\n\")\n",
        "    losses_test[t]=test_loss\n",
        "    accuracies[t][1] = (100*correct)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_transformer(config, checkpoint_dir=None):\n",
        "\n",
        "  model = TransformerModel(512, 512,1024, n_head=config[\"heads\"])\n",
        "\n",
        "  if torch.cuda.device_count() > 1:\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=config[\"lr\"], momentum = config[\"momentum\"])\n",
        "  #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.98), eps=1e-9)\n",
        "  train_dataloader = DataLoader(train_val_data[0], batch_size=batch_size, shuffle=True)\n",
        "  val_dataloader = DataLoader(train_val_data[1], batch_size=batch_size, shuffle=True)\n",
        "  test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, t)\n",
        "    validation_loop(val_dataloader,  model, loss_fn, optimizer, t,checkpoint_dir=checkpoint_dir)\n",
        "    test_loop(test_dataloader, model, loss_fn, t)\n",
        "  print(\"Done!\")"
      ],
      "metadata": {
        "id": "jpgdSAtjO9wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyzO1CzHGMve"
      },
      "outputs": [],
      "source": [
        "#Definiamo la loss function e il metodo di minimizzazione\n",
        "#learning_rate = 1e-3\n",
        "#momentum = 0.9\n",
        "batch_size = 64\n",
        "epochs = 4\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "  gpus_per_trial = 2\n",
        "else:\n",
        "  gpus_per_trial = 1\n",
        "\n",
        "#Definisco il blocco per la scelta degli iperparametri\n",
        "config = {\n",
        "        \"heads\": tune.sample_from(lambda _: 2 ** np.random.randint(1, 4)),\n",
        "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "        \"momentum\": tune.uniform(0.5, 0.9)\n",
        "}\n",
        "\n",
        "scheduler = ASHAScheduler(\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "\n",
        "reporter = CLIReporter(\n",
        "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
        "\n",
        "result = tune.run(\n",
        "        partial(train_transformer),\n",
        "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
        "        config=config,\n",
        "        num_samples=len(train_val_data[0]),\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter)\n",
        "\n",
        "best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "print(\"Best trial config: {}\".format(best_trial.config))\n",
        "print(\"Best trial final validation loss: {}\".format(\n",
        "best_trial.last_result[\"loss\"]))\n",
        "print(\"Best trial final validation accuracy: {}\".format(\n",
        "best_trial.last_result[\"accuracy\"]))\n",
        "\n",
        "best_trained_model = TransformerModel(512, 512,1024, n_head=config[\"heads\"])\n",
        "if gpus_per_trial > 1:\n",
        "  best_trained_model = nn.DataParallel(best_trained_model)\n",
        "\n",
        "best_checkpoint_dir = best_trial.checkpoint.value\n",
        "model_state, optimizer_state = torch.load(os.path.join(\n",
        "        best_checkpoint_dir, \"checkpoint\"))\n",
        "best_trained_model.load_state_dict(model_state)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import figure\n",
        "\n",
        "\n",
        "print(len(losses_train))\n",
        "\n",
        "fig1 = figure(figsize=(6,6), dpi=60)\n",
        "ax1 = fig1.add_subplot(111)\n",
        "ax1.set_xlabel(\"Batches\")\n",
        "ax1.set_ylabel(\"Loss value\")\n",
        "for i in range(epochs):\n",
        "    ep = \"Epoch {epo:5d}\"\n",
        "    ax1.plot(batches_time,losses_train[i,...], label=ep.format(epo=i+1))\n",
        "ax1.legend()\n",
        "\n",
        "\n",
        "fig2 = figure(figsize=(6,6), dpi=60)\n",
        "ax2 = fig2.add_subplot(111)\n",
        "ax2.set_xlabel(\"Epochs\")\n",
        "ax2.set_ylabel(\"Avg test loss\")\n",
        "ax2.plot( range(epochs), losses_test)\n",
        "\n",
        "fig3 = figure(figsize=(6,6), dpi=60)\n",
        "ax3 = fig3.add_subplot(111)\n",
        "ax3.set_xlabel(\"Epochs\")\n",
        "ax3.set_ylabel(\"Accuracy\")\n",
        "for i in range(2):\n",
        "  acc = \"Training accuracy\" if i == 0 else \"Test accuracy\"\n",
        "  ax3.plot(range(epochs),  accuracies[:,i], label=acc)\n",
        "ax3.legend()"
      ],
      "metadata": {
        "id": "OhH4J3Xt-yai"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFmlxBagIW9geitBzrsW4L",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}