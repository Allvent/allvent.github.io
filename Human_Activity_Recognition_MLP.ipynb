{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMx6zZNeIX8wf+FtCyvbvG/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Valent0296/allvent.github.io/blob/master/Human_Activity_Recognition_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Human activity recognition is the problem of classifying sequences of data recorded by specialized harnesses or smart phones into known well-defined Human activities.\n",
        "\n",
        "It is a challenging problem as the large number of observations are produced each second, the temporal nature of the observations, and the lack of a clear way to relate data to known movements increase the challenges."
      ],
      "metadata": {
        "id": "tygdalmHd84d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ebd0sHi0dRWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86aa961c-f05d-4807-cc12-5ecc71200eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append(\"/MyDrive/dataset/\")\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#carico i dati\n",
        "%cd /content/drive/MyDrive/dataset/\n",
        "train = pd.read_csv(\"train-1.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B1iom9QgT9O",
        "outputId": "538f8ab8-9670-4152-c45e-5b149755aa9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accorpo i dati per una base preliminare\n",
        "train['Data'] = 'Train'\n",
        "test['Data'] = 'Test'\n",
        "both = pd.concat( [train, test], axis=0 ).reset_index( drop=True )\n",
        "activity = dict(enumerate(both['Activity'].unique()))\n",
        "print(activity)\n",
        "act, un_act = pd.factorize( both['Activity'] )\n",
        "both['Activity'] = act\n",
        "\n",
        "def basic_details(df):\n",
        "  b = pd.DataFrame()\n",
        "  b['Missing Value'] = df.isnull().sum()\n",
        "  b['N unique value'] = df.nunique()\n",
        "  b['dtype'] = df.dtypes\n",
        "  return b\n",
        "features = len(both.drop(['Data','subject','Activity'], axis = 1).columns)\n",
        "print(features)\n",
        "bd = basic_details(both)\n",
        "activity = both['Activity']\n",
        "label_counts = activity.value_counts()\n",
        "print(label_counts)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.bar(label_counts.index, label_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "cZ8qdzQch83i",
        "outputId": "31bc2a77-0c60-4a9b-b6ca-ce6e0417d9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'STANDING', 1: 'SITTING', 2: 'LAYING', 3: 'WALKING', 4: 'WALKING_DOWNSTAIRS', 5: 'WALKING_UPSTAIRS'}\n",
            "561\n",
            "Activity\n",
            "2    1944\n",
            "0    1906\n",
            "1    1777\n",
            "3    1722\n",
            "5    1544\n",
            "4    1406\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PCA( train: pd.DataFrame, test: pd.DataFrame, retvar = 0.9):\n",
        "\n",
        "  cov = train.cov().values\n",
        "  mean = train.mean(axis=0)\n",
        "  eig, vec = np.linalg.eig(cov) #Calcolo autovalori e autovettori\n",
        "  eig, vec = np.real(eig), np.real(vec)\n",
        "  order = np.argsort( -eig )\n",
        "  evals = eig[order] #Ordino per grandezza del modulo\n",
        "\n",
        "  #Conta il numero di componenti principali che superano il 99.9% di variabilità\n",
        "  d = 1 + ( np.cumsum(evals) >= retvar * np.abs(evals.sum()) ).nonzero()[0][0]\n",
        "\n",
        "  #Costruisco la matrice di cambiamento di base w di dimensione n_features X d\n",
        "  w = vec[:, order[:d]]\n",
        "  return [np.matmul( (train - mean).values, w ), np.matmul( (test - mean).values, w ),np.divide( np.cumsum(evals), evals.sum())]\n",
        "\n",
        "\n",
        "class HARDataset( Dataset ):\n",
        "\n",
        "  def __init__(self, data, transform = None, target_transform = None):\n",
        "    if not(isinstance( data, pd.DataFrame )):\n",
        "      self.data_tensor = pd.DataFrame(data)\n",
        "    else:\n",
        "      self.data_tensor = data\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_tensor)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if not(isinstance( self.data_tensor['Activity'], int  )):\n",
        "      act, self.un_act = pd.factorize( self.data_tensor['Activity'] )\n",
        "      self.data_tensor['Activity'] = act\n",
        "    data = torch.Tensor( self.data_tensor.drop(['Data','subject','Activity'], axis = 1).to_numpy() )\n",
        "    label = torch.Tensor( self.data_tensor['Activity'].to_numpy() )\n",
        "    return data[idx,:], label[idx]\n",
        "\n",
        "#Normalizzo l'insieme totale di valori\n",
        "norm_both = both.drop(['Data','subject','Activity'], axis = 1)\n",
        "\n",
        "mean = both.drop(['Data','subject','Activity'], axis = 1).mean(axis=0)\n",
        "var = both.drop(['Data','subject','Activity'], axis = 1).var(axis=0)\n",
        "\n",
        "norm_both.add( -mean)\n",
        "norm_both.div(var)\n",
        "\n",
        "norm_both['Activity'] = act\n",
        "\n",
        "\n",
        "#train_n = np.column_stack((train_n, np.expand_dims(train_lab, -1)))\n",
        "#test_n = np.column_stack((test_n, np.expand_dims(test_lab, -1)))\n",
        "\n",
        "\n",
        "#print(norm_both)\n",
        "\n"
      ],
      "metadata": {
        "id": "qfVqIOSMk4fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list_train = []\n",
        "loss_list_test = []\n",
        "acc_list_train = []\n",
        "acc_list_test = []\n",
        "n_batch = 64\n",
        "\n",
        "#Define train and test loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  model.train()\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    batch_size, correct = 0, 0\n",
        "    X, y = X.to(device), y.to(device).to(torch.long)\n",
        "    one_hot_label = nn.functional.one_hot(y, num_classes=len(label_counts))\n",
        "    #Compute prediction and loss\n",
        "    pred = model(X) #torch.argmin(model(X) , -1).to(torch.long)\n",
        "    loss = loss_fn(pred, y)\n",
        "    train_label = torch.argmin(model(X) , -1)\n",
        "    correct = (train_label==y).type(torch.int).sum().item()\n",
        "    batch_size = X.size(0)\n",
        "    correct /= batch_size\n",
        "    acc_list_train.append(correct) #Take note of the single batch accuracy\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_list_train.append(loss.item()) #\n",
        "    if batch % 10 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"Funzione di loss: {loss:>7f} Errore train: \\n Accuratezza: {(100*correct):>0.1f}%, [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "    one_hot_label = torch.zeros(n_batch, len(label_counts))\n",
        "    with torch.no_grad():\n",
        "      for X, y in dataloader:\n",
        "        batch_size, correct_batch =0, 0\n",
        "        X, y = X.to(device), y.to(device).to(torch.long)\n",
        "        one_hot_label[:,y] = 1\n",
        "        #Compute prediction and loss\n",
        "        pred = model(X) #torch.argmin(model(X) , -1).to(torch.long)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss_list_test.append(loss.item()) #Take note of the single batch loss\n",
        "        test_loss +=loss_fn(pred, y).item()\n",
        "        test_label = torch.argmin(model(X) , -1)\n",
        "        correct += (test_label==y).type(torch.int).sum().item()\n",
        "        correct_batch = (test_label==y).type(torch.int).sum().item()\n",
        "        batch_size = X.size(0)\n",
        "        correct_batch /= batch_size\n",
        "        acc_list_test.append(correct_batch) #Take note of the batch accuracy\n",
        "\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= num_batches\n",
        "    print(f\"Errore test: \\n Accuratezza: {(100*correct):>0.1f}%, Media loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "#Define train and test loop\n",
        "def dev_loop(dataloader, model, loss_fn, optimizer):\n",
        "  model.train()\n",
        "  size = len(dataloader.dataset)\n",
        "  dev_loss, correct = 0.0, 0.0\n",
        "  num_batches = len(dataloader)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    batch_size, batch_correct = 0, 0\n",
        "    X, y = X.to(device), y.to(device).to(torch.long)\n",
        "    one_hot_label = nn.functional.one_hot(y, num_classes=len(label_counts))\n",
        "    #Compute prediction and loss\n",
        "    pred = model(X) #torch.argmin(model(X) , -1).to(torch.long)\n",
        "    loss = loss_fn(pred, y)\n",
        "    dev_loss += loss\n",
        "    train_label = torch.argmin(model(X) , -1)\n",
        "    batch_correct = (train_label==y).type(torch.int).sum().item()\n",
        "    correct += batch_correct\n",
        "    batch_size = X.size(0)\n",
        "    batch_correct /= batch_size\n",
        "    acc_list_train.append(correct) #Take note of the single batch accuracy\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_list_train.append(loss.item()) #\n",
        "\n",
        "  dev_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Errore dev: \\n Accuratezza: {(100*correct):>0.1f}%, Media loss: {dev_loss:>8f} \\n\")\n",
        "  return correct"
      ],
      "metadata": {
        "id": "Uhq6ybs1Fx-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = features\n",
        "\n",
        "class FixModel(nn.Module):\n",
        "\n",
        "  def __init__(self, n_features: int, n_hidden: int=4096, n_layers:int = 8, dropout: float=0.5):\n",
        "      super().__init__()\n",
        "      self.model_type = \"FFN\"\n",
        "      self.n_features = n_features\n",
        "      self.n_hidden = n_hidden\n",
        "      self.n_layers = n_layers\n",
        "\n",
        "      self.lin_soft_stack_1 = [nn.Sequential(\n",
        "          nn.Linear(int(n_hidden/2**(i)), int(n_hidden/2**(i+1))),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(int(n_hidden/2**(i+1)), int(n_hidden/2**(i+1))),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(int(n_hidden/2**(i+1)), int(n_hidden/2**(i+1))),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout),\n",
        "          nn.BatchNorm1d(int(n_hidden/2**(i+1)))\n",
        "      ) for i in range(self.n_layers)]\n",
        "      self.lin_soft_stack_2 = self.lin_soft_stack_1\n",
        "      self.lin_soft_stack_3 = self.lin_soft_stack_1\n",
        "\n",
        "      self.lin_soft_stack_zero = nn.Sequential(\n",
        "          nn.Linear(n_features, n_hidden),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(n_hidden, n_hidden),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(n_hidden, n_hidden),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout),\n",
        "          nn.BatchNorm1d(n_hidden)\n",
        "      )\n",
        "      self.mid_lin_stack_1 = nn.Sequential(nn.Linear(int(n_hidden/2**(self.n_layers)), int(n_hidden/2**(self.n_layers)), nn.ReLU()))\n",
        "\n",
        "      self.fin_lin_stack = nn.Sequential(nn.Linear(int(n_hidden/2**(self.n_layers)), len(un_act)), nn.Softmax(-1))\n",
        "\n",
        "  def forward(self, src: Tensor) -> Tensor:\n",
        "\n",
        "    first_input = self.lin_soft_stack_zero(src).to(device)\n",
        "    first_input = first_input + nn.Sequential(nn.Linear(self.n_features, self.n_hidden),nn.ReLU()).to(device)(src)\n",
        "\n",
        "    prec_input_first_stack = first_input\n",
        "    prec_input_second_stack = first_input\n",
        "    prec_input_third_stack = first_input\n",
        "    for i in range(self.n_layers):\n",
        "        input_first_stack = self.lin_soft_stack_1[i].to(device)(prec_input_first_stack)\n",
        "        input_first_stack = input_first_stack + nn.Sequential(nn.Linear(int(self.n_hidden/2**(i)), int(self.n_hidden/2**(i+1))),nn.ReLU()).to(device)(prec_input_first_stack)\n",
        "        prec_input_first_stack = input_first_stack\n",
        "\n",
        "        input_second_stack = self.lin_soft_stack_2[i].to(device)(prec_input_second_stack)\n",
        "        input_second_stack = input_second_stack + nn.Sequential(nn.Linear(int(self.n_hidden/2**(i)), int(self.n_hidden/2**(i+1))),nn.ReLU()).to(device)(prec_input_second_stack)\n",
        "        prec_input_second_stack = input_second_stack\n",
        "\n",
        "        input_third_stack = self.lin_soft_stack_3[i].to(device)(prec_input_third_stack)\n",
        "        input_third_stack = input_third_stack + nn.Sequential(nn.Linear(int(self.n_hidden/2**(i)), int(self.n_hidden/2**(i+1))),nn.ReLU()).to(device)(prec_input_third_stack)\n",
        "        prec_input_third_stack = input_third_stack\n",
        "\n",
        "    mid_stack = nn.Softmax(-1)(input_first_stack*input_second_stack/int(self.n_hidden/2**(self.n_layers-1))**(1/2)).to(device)*input_third_stack\n",
        "    mid_stack = self.mid_lin_stack_1(mid_stack)\n",
        "\n",
        "    output = self.fin_lin_stack(mid_stack)\n",
        "    return output\n",
        "\n",
        "model_1 = FixModel(n_features).to(device)\n",
        "\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight).to(device)\n",
        "        m.bias.data.fill_(0.01).to(device)\n",
        "\n",
        "model_1.apply(init_weights)\n",
        "model_1.to(device)"
      ],
      "metadata": {
        "id": "0IP3EKe0qfzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3acb8ee9-d109-415c-e2f4-f9ad2242051e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FixModel(\n",
              "  (lin_soft_stack_zero): Sequential(\n",
              "    (0): Linear(in_features=561, out_features=4096, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Dropout(p=0.5, inplace=False)\n",
              "    (7): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (mid_lin_stack_1): Sequential(\n",
              "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (fin_lin_stack): Sequential(\n",
              "    (0): Linear(in_features=16, out_features=6, bias=True)\n",
              "    (1): Softmax(dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_frac = 0.01\n",
        "test_frac = 0.01\n",
        "train_frac = 1 - dev_frac - test_frac\n",
        "batch_size = 64\n",
        "\n",
        "#Mischio il dataframe (estraggo in maniera casuale tutte le righe del DataFrame)\n",
        "both = both.sample(n=len(both))\n",
        "\n",
        "#Creo i dataset per dev-train-set\n",
        "train = both.sample(frac=train_frac)\n",
        "test = both.sample(frac=test_frac)\n",
        "dev = both.sample(frac=dev_frac)\n",
        "\n",
        "train_dataset = HARDataset(train)\n",
        "test_dataset = HARDataset(test)\n",
        "dev_dataset = HARDataset(dev)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#Definiamo la loss function, metodo di minimizzazione e iperparametri\n",
        "learning_rate = [10**(-i) for i in range(1,5)]\n",
        "momentum = [i/10 for i in range(10)]\n",
        "lr_mom_grid = [(l,m, 0) for l in learning_rate for m in momentum]\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(model_1.parameters(), lr=learning_rate)\n",
        "#optimizer = torch.optim.SGD(model_1.parameters(), lr=learning_rate, momentum = momentum)\n",
        "\n",
        "for i, (l, m, a) in enumerate(lr_mom_grid):\n",
        "  print(f\"Learning rate: {l}, Momentum: {m}\")\n",
        "  optimizer = torch.optim.SGD(model_1.parameters(), lr=l, momentum = m)\n",
        "  epochs = 1\n",
        "  for t in range(epochs):\n",
        "      print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "      a += dev_loop(dev_dataloader, model_1, loss_fn, optimizer)\n",
        "\n",
        "  a /= epochs\n",
        "  lr_mom_grid[i] = (l,m, a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4t_LbjAkJPMP",
        "outputId": "7a1ccc4d-9dbc-4350-e748-6cc40899057f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.1, Momentum: 0.0\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Errore dev: \n",
            " Accuratezza: 19.4%, Media loss: 1.789362 \n",
            "\n",
            "Learning rate: 0.1, Momentum: 0.1\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Errore dev: \n",
            " Accuratezza: 20.4%, Media loss: 1.793154 \n",
            "\n",
            "Learning rate: 0.1, Momentum: 0.2\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Errore dev: \n",
            " Accuratezza: 11.7%, Media loss: 1.793347 \n",
            "\n",
            "Learning rate: 0.1, Momentum: 0.3\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Errore dev: \n",
            " Accuratezza: 11.7%, Media loss: 1.794043 \n",
            "\n",
            "Learning rate: 0.1, Momentum: 0.4\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Errore dev: \n",
            " Accuratezza: 17.5%, Media loss: 1.791581 \n",
            "\n",
            "Learning rate: 0.1, Momentum: 0.5\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Errore dev: \n",
            " Accuratezza: 17.5%, Media loss: 1.790801 \n",
            "\n",
            "Learning rate: 0.1, Momentum: 0.6\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Errore dev: \n",
            " Accuratezza: 13.6%, Media loss: 1.791884 \n",
            "\n",
            "Learning rate: 0.1, Momentum: 0.7\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Errore dev: \n",
            " Accuratezza: 19.4%, Media loss: 1.792111 \n",
            "\n",
            "Learning rate: 0.1, Momentum: 0.8\n",
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-3f8f86c5ed8b>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m       \u001b[0ma\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdev_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-f1b94365d11b>\u001b[0m in \u001b[0;36mdev_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mdev_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mbatch_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-fb21dab37793>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0minput_third_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_soft_stack_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec_input_third_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0minput_third_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_third_stack\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec_input_third_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mprec_input_third_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_third_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# https://github.com/pytorch/pytorch/issues/57109\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity, generator)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the development accuracy doesn't reach 20% despite the model complexity. The classsification using a multilayer perceptron is a failure"
      ],
      "metadata": {
        "id": "DdvuxKHnlC7f"
      }
    }
  ]
}