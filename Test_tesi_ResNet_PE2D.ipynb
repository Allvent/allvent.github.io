{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Valent0296/allvent.github.io/blob/master/Test_tesi_ResNet_PE2D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1bu_WTjGgq5",
        "outputId": "d07ad0c4-1743-4d72-db55-7ddcf49905bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#IMPORTO LA CARTELLA MATH_LOADER CON RELATIVI CONTENUTI DALLA LOCATION DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/MyDrive/math_loader/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNpVkeZy79d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84f90b84-ea9f-4a82-c632-68ba3bde4792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (5): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (6): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (7): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (8): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = nn.Sequential(\n",
        "    models.resnet18(pretrained=True).conv1,\n",
        "    models.resnet18(pretrained=True).bn1,\n",
        "    models.resnet18(pretrained=True).relu,\n",
        "    models.resnet18(pretrained=True).maxpool,\n",
        "    models.resnet18(pretrained=True).layer1,\n",
        "    models.resnet18(pretrained=True).layer2,\n",
        "    models.resnet18(pretrained=True).layer3,\n",
        "    models.resnet18(pretrained=True).layer4,\n",
        "    models.resnet18(pretrained=True).avgpool\n",
        ").to(device)\n",
        "\n",
        "model_ft.add_module(\"0\", nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)))\n",
        "model_ft.add_module(\"8\", nn.AdaptiveAvgPool2d(output_size=(6,6)))\n",
        "model_ft.get_submodule(\"7\").get_submodule(\"0\").get_submodule(\"downsample\").add_module(\"0\", nn.Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False))\n",
        "model_ft.get_submodule(\"7\").get_submodule(\"0\").get_submodule(\"downsample\").add_module(\"1\", nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
        "model_ft.get_submodule(\"7\").get_submodule(\"0\").add_module(\"conv2\", nn.Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
        "model_ft.get_submodule(\"7\").get_submodule(\"0\").add_module(\"bn2\", nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
        "model_ft.get_submodule(\"7\").get_submodule(\"1\").add_module(\"conv1\", nn.Conv2d( 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
        "model_ft.get_submodule(\"7\").get_submodule(\"1\").add_module(\"conv2\", nn.Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
        "model_ft.get_submodule(\"7\").get_submodule(\"1\").add_module(\"bn2\", nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
        "for idx, name in enumerate(model_ft.modules()):\n",
        "  name.requires_grad_(True)\n",
        "print(model_ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfSobE_EH0BY",
        "outputId": "b6250d36-df8c-4c18-f7d6-c233ff930caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1yEYXJtFSq_AJGXoLWG9r6AGr2yS9iSIt/math_dataloader\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/math_dataloader/\n",
        "import data as d\n",
        "import language as l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-xqayIz3N2A"
      },
      "outputs": [],
      "source": [
        "filename = [\"data/\" + fi for fi in [\"train.txt\", \"test.txt\", \"validation.txt\"]]\n",
        "\n",
        "training = True\n",
        "height = 160\n",
        "width = 1600\n",
        "dataset=[]\n",
        "for i in range(3):\n",
        "  training = True if i == 1 else False\n",
        "  dataset.append(d.ExprDataset(\"data/\", filename[i], training, height,\n",
        "                          width, geometric_var=0.05,\n",
        "                          photometric_var=0.25))\n",
        "n_tok = len(dataset[0].tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2bblKi7ajrlA",
        "outputId": "f473d23d-d46e-42ff-9b2a-b98e3f69aebe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for images, codes, paths in test_dataloader:\\n  print(codes.size())'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_dataloader = DataLoader(dataset[0], batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset[1], batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset[2], batch_size=64, shuffle=True)\n",
        "\"\"\"for images, codes, paths in test_dataloader:\n",
        "  print(codes.size())\"\"\"\n",
        "#VEDERE PERCHé ALCUNE IMMAGINI NON VENGONO CARICATE, E CAPIRE PERCHÈ LE DIMENSIONI DANNO PROBLEMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYH4tKyo967b"
      },
      "outputs": [],
      "source": [
        "##################################\n",
        "# Positional Encoding for Tokens #\n",
        "##################################\n",
        "class PositionalEncoding( nn.Module ):\n",
        "\n",
        "  def __init__( self, d_model: int=256, dropout: float=0.1, maxlen: int=10 ):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    den = torch.exp( torch.arange( 0, d_model, 2 ) * ( -math.log(10000) / d_model ) )\n",
        "    pos = torch.arange(0, maxlen).reshape( maxlen, 1 )\n",
        "    self.pe = torch.zeros( (maxlen, d_model) ).to(device)\n",
        "    self.pe[:, 0::2] = torch.sin(pos*den)\n",
        "    self.pe[:, 1::2] = torch.cos(pos*den)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\"pos_enc\", self.pe)\n",
        "\n",
        "  def forward(self, ccn_embed: Tensor):\n",
        "    return self.dropout( ccn_embed + self.pe )\n",
        "\n",
        "######################################\n",
        "# Positional Encoding for Embeddings #\n",
        "######################################\n",
        "class PositionalEncoding2D( nn.Module ):\n",
        "\n",
        "  def __init__( self, d_model: int=256, dropout: float=0.1, height: int=10, width: int=10 ):\n",
        "    super(PositionalEncoding2D, self).__init__()\n",
        "    \"\"\"\n",
        "    :param d_model: dimension of the model\n",
        "    :param height: height of the positions\n",
        "    :param width: width of the positions\n",
        "    :return: d_model*height*width position matrix\n",
        "    \"\"\"\n",
        "    if d_model % 4 != 0:\n",
        "        raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
        "                         \"odd dimension (got dim={:d})\".format(d_model))\n",
        "    self.pe = torch.zeros(d_model, height, width).to(device)\n",
        "    # Each dimension use half of d_model\n",
        "    d_model = int(d_model / 2)\n",
        "    div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
        "                         -(math.log(10000.0) / d_model))\n",
        "    pos_w = torch.arange(0., width).unsqueeze(1)\n",
        "    pos_h = torch.arange(0., height).unsqueeze(1)\n",
        "    self.pe[0:d_model:2, :, :] = torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "    self.pe[1:d_model:2, :, :] = torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "    self.pe[d_model::2, :, :] = torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "    self.pe[d_model + 1::2, :, :] = torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\"pos_enc\", self.pe)\n",
        "\n",
        "  def forward(self, ccn_embed: Tensor):\n",
        "    return self.dropout( ccn_embed + self.pe)\n",
        "\n",
        "\n",
        "###################\n",
        "# Input embedding #\n",
        "###################\n",
        "class SampleEmbedding( nn.Module ):\n",
        "\n",
        "  def __init__(self, d_emb: int=256):\n",
        "      super(SampleEmbedding, self).__init__()\n",
        "      self.ccn = model_ft\n",
        "\n",
        "  def forward(self, blocks: Tensor):\n",
        "    return torch.utils.checkpoint.checkpoint_sequential(self.ccn, 5, blocks).to(device)\n",
        "\n",
        "##################\n",
        "# Token Embedder #\n",
        "##################\n",
        "class TokenEmbedding(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size: int, d_model: int):\n",
        "    super(TokenEmbedding, self).__init__()\n",
        "    self.embedder = nn.Embedding(vocab_size, d_model)\n",
        "    self.emb_size = d_model\n",
        "\n",
        "  def forward(self, tokens: Tensor):\n",
        "    return self.embedder( tokens.long() ) * math.sqrt(self.emb_size).to(device)\n",
        "\n",
        "###########\n",
        "# Masking #\n",
        "###########\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    #generetes a triangular upper matrix for attention masking\n",
        "    mask = (torch.triu(torch.ones((sz, sz))) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def create_pad_mask( matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
        "    # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
        "    # [False, False, False, True, True, True]\n",
        "    return (matrix == pad_token)\n",
        "\n",
        "############\n",
        "# Accuracy #\n",
        "############\n",
        "def batch_accuracy_calculate( pred: Tensor, y: Tensor):\n",
        "\n",
        "  corr = 0\n",
        "  tot = 0\n",
        "  for p, label in zip(pred[:] ,y[:]):\n",
        "\n",
        "\n",
        "    for tok_p, tok_l in zip(p[:], label[:]):\n",
        "\n",
        "\n",
        "      if tok_p.item() != 3 and tok_l.item() != 3:\n",
        "        corr += (tok_p == tok_l).type(torch.int).sum().item()\n",
        "        tot += 1\n",
        "\n",
        "\n",
        "      else:\n",
        "        return [corr, tot]\n",
        "\n",
        "  return [corr, tot]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClZ_t2igvmhl"
      },
      "outputs": [],
      "source": [
        "##############\n",
        "# Tranformer #\n",
        "##############\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "  def __init__(self, ntokens: int, d_mod: int, d_hid: int ,n_head: int=8, dropout: float=0.5):\n",
        "      super().__init__()\n",
        "      self.model_type = \"Transformer\"\n",
        "      self.nhead = n_head\n",
        "      self.d_model = d_mod\n",
        "      self.src_embedding = SampleEmbedding(d_mod)\n",
        "      self.pos_encod = PositionalEncoding2D(d_mod, dropout, 6, 6)\n",
        "      self.tgt_encod = PositionalEncoding(d_mod, dropout, maxlen=20)\n",
        "      self.tgt_embed = nn.Embedding(n_tok,d_mod)\n",
        "      self.flat = nn.Flatten(start_dim=2)\n",
        "      encoder_layer = nn.TransformerEncoderLayer( d_mod, n_head, d_hid, batch_first=True )\n",
        "      self.transformer_encoder = nn.TransformerEncoder(encoder_layer, n_head)\n",
        "      decoder_layer = nn.TransformerDecoderLayer( d_mod, n_head, dropout=dropout, batch_first=True)\n",
        "      self.transformer_decoder = nn.TransformerDecoder(decoder_layer, n_head )\n",
        "      self.lin_soft_stack = nn.Sequential(\n",
        "          nn.Linear(d_mod, ntokens),\n",
        "          nn.Softmax(dim=1)\n",
        "      )\n",
        "\n",
        "  def forward(self, src: Tensor, tgt: Tensor, tgt_mask: Tensor, pad_mask: Tensor) -> Tensor:\n",
        "\n",
        "    src_emb = []\n",
        "    for i in range(src.size(0)):\n",
        "      src_emb.append(self.src_embedding(src[i,:,:].unsqueeze(1)) * math.sqrt(self.d_model) )\n",
        "    src_embed_tensor = torch.stack(src_emb).squeeze()\n",
        "    tgt = self.tgt_embed(tgt) * math.sqrt(self.d_model)\n",
        "    src_embed_tensor = self.pos_encod(src_embed_tensor)\n",
        "    tgt = self.tgt_encod(tgt)\n",
        "    src_embed_tensor = self.flat(src_embed_tensor)\n",
        "    memory = self.transformer_encoder(src_embed_tensor.permute(0,2,1))\n",
        "    deco = self.transformer_decoder(tgt, memory, tgt_mask=tgt_mask, tgt_key_padding_mask=pad_mask)\n",
        "    output = self.lin_soft_stack(deco)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOmh8Ntq-SNz"
      },
      "outputs": [],
      "source": [
        "#d_mod = n_channels = 256 (embedding dimensions)\n",
        "model = TransformerModel(n_tok, 256,1024).to(device)\n",
        "model = torch.nn.DataParallel(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48akcIKuCSC_"
      },
      "outputs": [],
      "source": [
        "loss_list_train = []\n",
        "loss_list_test = []\n",
        "acc_list_train = []\n",
        "acc_list_test = []\n",
        "\n",
        "#Define train and test loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  model.train()\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y, paths) in enumerate(dataloader):\n",
        "    size, correct = 0, 0\n",
        "    X, y = X.to(device), y.to(device) # X.size() == (batch_size, height, width); y.size() == (batch_size, seq_length)\n",
        "    tgt_mask = generate_square_subsequent_mask(y.size(1))\n",
        "    pad_mask = create_pad_mask(y, 3)\n",
        "\n",
        "    #Compute prediction and loss\n",
        "    pred = model(X, y, tgt_mask, pad_mask) # pred.size() == (batch_size, seq_length, d_mod)\n",
        "    loss = loss_fn(pred.permute(0,2,1), y)\n",
        "    acc_pack = batch_accuracy_calculate(pred.argmax(2), y) # pred is maximized along d_mod dimension allowing comparison with y\n",
        "    correct += acc_pack[0]\n",
        "    size += acc_pack[1]\n",
        "    correct /= size\n",
        "    acc_list_train.append(correct) #Take note of the single batch accuracy\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_list_train.append(loss.item()) #\n",
        "    if batch % 10 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"Funzione di loss: {loss:>7f} [{current:>5d}/{size:>5d}/8300]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = 0\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for X, y, paths in dataloader:\n",
        "        batch_size, correct_batch =0, 0\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        tgt_mask = generate_square_subsequent_mask(y.size(1))\n",
        "        pad_mask = create_pad_mask(y, 3)\n",
        "        #Compute prediction and loss\n",
        "        pred = model(X, y, tgt_mask, pad_mask)\n",
        "        loss = loss_fn(pred.permute(0,2,1), y)\n",
        "        loss_list_test.append(loss.item()) #Take note of the single batch loss\n",
        "        test_loss += loss_fn(pred.permute(0,2,1), y).item()\n",
        "        acc_pack = batch_accuracy_calculate(pred.argmax(2), y) # pred is maximized along d_mod dimension allowing comparison with y\n",
        "        correct += acc_pack[0]\n",
        "        correct_batch += acc_pack[0]\n",
        "        size += acc_pack[1]\n",
        "        batch_size += acc_pack[1]\n",
        "        correct_batch /= batch_size\n",
        "        acc_list_test.append(correct_batch) #Take note of the batch accuracy\n",
        "\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Errore test: \\n Accuratezza: {(100*correct):>0.1f}%, Media loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyzO1CzHGMve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6889107a-d820-444e-abae-e901f60a7f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Funzione di loss: 4.605437 [    0/    9/8300]\n",
            "Funzione di loss: 4.605071 [  640/   10/8300]\n",
            "Funzione di loss: 4.603691 [ 1280/   15/8300]\n",
            "Funzione di loss: 4.602553 [ 1920/   53/8300]\n",
            "Funzione di loss: 4.597796 [ 2560/   15/8300]\n",
            "Funzione di loss: 4.583098 [ 3200/   10/8300]\n",
            "Funzione di loss: 4.546018 [ 3840/   13/8300]\n",
            "Funzione di loss: 4.532440 [ 4480/   14/8300]\n",
            "Funzione di loss: 4.523986 [ 5120/   15/8300]\n",
            "Funzione di loss: 4.475482 [ 5760/   13/8300]\n",
            "Funzione di loss: 4.445719 [ 6400/   15/8300]\n",
            "Funzione di loss: 4.396024 [ 7040/   11/8300]\n",
            "Funzione di loss: 4.361186 [ 7680/   10/8300]\n",
            "Errore test: \n",
            " Accuratezza: 57.8%, Media loss: 4.307397 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Funzione di loss: 4.322335 [    0/   19/8300]\n",
            "Funzione di loss: 4.314105 [  640/    9/8300]\n",
            "Funzione di loss: 4.296843 [ 1280/   17/8300]\n",
            "Funzione di loss: 4.255865 [ 1920/   16/8300]\n",
            "Funzione di loss: 4.193407 [ 2560/   17/8300]\n",
            "Funzione di loss: 4.194396 [ 3200/   17/8300]\n",
            "Funzione di loss: 4.192110 [ 3840/   15/8300]\n",
            "Funzione di loss: 4.134767 [ 4480/   36/8300]\n",
            "Funzione di loss: 4.139315 [ 5120/   17/8300]\n",
            "Funzione di loss: 4.117166 [ 5760/   37/8300]\n",
            "Funzione di loss: 4.098415 [ 6400/   12/8300]\n",
            "Funzione di loss: 4.109736 [ 7040/    7/8300]\n",
            "Funzione di loss: 4.068439 [ 7680/   36/8300]\n",
            "Errore test: \n",
            " Accuratezza: 78.3%, Media loss: 4.055727 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Funzione di loss: 4.083839 [    0/   35/8300]\n",
            "Funzione di loss: 4.093982 [  640/   15/8300]\n",
            "Funzione di loss: 4.078308 [ 1280/   59/8300]\n",
            "Funzione di loss: 4.083486 [ 1920/   13/8300]\n",
            "Funzione di loss: 4.089135 [ 2560/   33/8300]\n",
            "Funzione di loss: 4.056271 [ 3200/   16/8300]\n",
            "Funzione di loss: 4.046491 [ 3840/   18/8300]\n",
            "Funzione di loss: 4.068646 [ 4480/   15/8300]\n",
            "Funzione di loss: 4.023921 [ 5120/    7/8300]\n",
            "Funzione di loss: 4.026240 [ 5760/   15/8300]\n",
            "Funzione di loss: 4.038239 [ 6400/   58/8300]\n",
            "Funzione di loss: 4.005180 [ 7040/   17/8300]\n",
            "Funzione di loss: 4.039472 [ 7680/   11/8300]\n",
            "Errore test: \n",
            " Accuratezza: 93.6%, Media loss: 3.980853 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Funzione di loss: 3.994300 [    0/   12/8300]\n",
            "Funzione di loss: 4.008353 [  640/   11/8300]\n",
            "Funzione di loss: 4.009413 [ 1280/   30/8300]\n",
            "Funzione di loss: 4.011619 [ 1920/   35/8300]\n",
            "Funzione di loss: 4.021568 [ 2560/   35/8300]\n",
            "Funzione di loss: 4.007788 [ 3200/   17/8300]\n",
            "Funzione di loss: 4.042970 [ 3840/   11/8300]\n",
            "Funzione di loss: 3.999815 [ 4480/   11/8300]\n",
            "Funzione di loss: 3.985886 [ 5120/   15/8300]\n",
            "Funzione di loss: 4.032266 [ 5760/   15/8300]\n",
            "Funzione di loss: 3.995083 [ 6400/   14/8300]\n",
            "Funzione di loss: 3.998671 [ 7040/   11/8300]\n",
            "Funzione di loss: 3.965205 [ 7680/   12/8300]\n",
            "Errore test: \n",
            " Accuratezza: 91.2%, Media loss: 3.984757 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Funzione di loss: 4.005112 [    0/   13/8300]\n",
            "Funzione di loss: 3.977695 [  640/   32/8300]\n",
            "Funzione di loss: 3.976138 [ 1280/   18/8300]\n",
            "Funzione di loss: 3.993856 [ 1920/   15/8300]\n",
            "Funzione di loss: 3.991227 [ 2560/   15/8300]\n",
            "Funzione di loss: 4.005313 [ 3200/   16/8300]\n",
            "Funzione di loss: 4.011856 [ 3840/    7/8300]\n",
            "Funzione di loss: 3.972328 [ 4480/   34/8300]\n",
            "Funzione di loss: 3.981054 [ 5120/    7/8300]\n",
            "Funzione di loss: 3.976011 [ 5760/   11/8300]\n",
            "Funzione di loss: 3.974044 [ 6400/   12/8300]\n",
            "Funzione di loss: 4.022081 [ 7040/   32/8300]\n",
            "Funzione di loss: 3.990327 [ 7680/   11/8300]\n",
            "Errore test: \n",
            " Accuratezza: 91.1%, Media loss: 3.980738 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Funzione di loss: 4.007061 [    0/   29/8300]\n",
            "Funzione di loss: 3.966177 [  640/    9/8300]\n",
            "Funzione di loss: 3.972129 [ 1280/   18/8300]\n",
            "Funzione di loss: 3.992959 [ 1920/    9/8300]\n",
            "Funzione di loss: 3.994214 [ 2560/   32/8300]\n",
            "Funzione di loss: 3.980899 [ 3200/    8/8300]\n",
            "Funzione di loss: 3.991477 [ 3840/   30/8300]\n",
            "Funzione di loss: 3.982520 [ 4480/    9/8300]\n",
            "Funzione di loss: 4.008124 [ 5120/   36/8300]\n",
            "Funzione di loss: 3.997357 [ 5760/   37/8300]\n",
            "Funzione di loss: 3.982153 [ 6400/   49/8300]\n",
            "Funzione di loss: 4.022471 [ 7040/   16/8300]\n",
            "Funzione di loss: 4.007657 [ 7680/   16/8300]\n",
            "Errore test: \n",
            " Accuratezza: 92.9%, Media loss: 3.985417 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Funzione di loss: 3.983678 [    0/   11/8300]\n",
            "Funzione di loss: 3.971490 [  640/   13/8300]\n",
            "Funzione di loss: 3.961110 [ 1280/   31/8300]\n",
            "Funzione di loss: 3.987647 [ 1920/   11/8300]\n",
            "Funzione di loss: 4.002085 [ 2560/   18/8300]\n",
            "Funzione di loss: 3.989178 [ 3200/   55/8300]\n",
            "Funzione di loss: 4.024697 [ 3840/   13/8300]\n",
            "Funzione di loss: 3.988540 [ 4480/   15/8300]\n",
            "Funzione di loss: 4.000953 [ 5120/   18/8300]\n",
            "Funzione di loss: 3.974783 [ 5760/   17/8300]\n",
            "Funzione di loss: 3.988863 [ 6400/   13/8300]\n",
            "Funzione di loss: 4.006871 [ 7040/   12/8300]\n",
            "Funzione di loss: 4.008638 [ 7680/   15/8300]\n",
            "Errore test: \n",
            " Accuratezza: 91.0%, Media loss: 3.975682 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Funzione di loss: 3.989614 [    0/   52/8300]\n",
            "Funzione di loss: 3.974083 [  640/   19/8300]\n",
            "Funzione di loss: 3.972779 [ 1280/   19/8300]\n",
            "Funzione di loss: 3.973455 [ 1920/   11/8300]\n",
            "Funzione di loss: 3.996793 [ 2560/   37/8300]\n",
            "Funzione di loss: 3.985797 [ 3200/   38/8300]\n",
            "Funzione di loss: 3.946541 [ 3840/   28/8300]\n",
            "Funzione di loss: 3.956262 [ 4480/   29/8300]\n",
            "Funzione di loss: 3.961654 [ 5120/   14/8300]\n",
            "Funzione di loss: 3.955418 [ 5760/   11/8300]\n",
            "Funzione di loss: 4.010606 [ 6400/   33/8300]\n",
            "Funzione di loss: 3.970785 [ 7040/   16/8300]\n",
            "Funzione di loss: 3.966893 [ 7680/   17/8300]\n",
            "Errore test: \n",
            " Accuratezza: 92.5%, Media loss: 3.973096 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Funzione di loss: 3.939640 [    0/  136/8300]\n",
            "Funzione di loss: 3.985881 [  640/   32/8300]\n",
            "Funzione di loss: 3.976140 [ 1280/   57/8300]\n",
            "Funzione di loss: 3.980779 [ 1920/   15/8300]\n",
            "Funzione di loss: 4.005277 [ 2560/   31/8300]\n",
            "Funzione di loss: 3.978675 [ 3200/   16/8300]\n",
            "Funzione di loss: 3.951793 [ 3840/   54/8300]\n",
            "Funzione di loss: 3.977242 [ 4480/   11/8300]\n",
            "Funzione di loss: 3.986212 [ 5120/   19/8300]\n",
            "Funzione di loss: 3.983604 [ 5760/   35/8300]\n",
            "Funzione di loss: 4.001981 [ 6400/   71/8300]\n",
            "Funzione di loss: 3.962501 [ 7040/   36/8300]\n",
            "Funzione di loss: 3.957632 [ 7680/   16/8300]\n",
            "Errore test: \n",
            " Accuratezza: 96.6%, Media loss: 3.978451 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Funzione di loss: 3.966454 [    0/   73/8300]\n",
            "Funzione di loss: 3.986922 [  640/   69/8300]\n",
            "Funzione di loss: 3.981329 [ 1280/   15/8300]\n",
            "Funzione di loss: 3.978244 [ 1920/    8/8300]\n",
            "Funzione di loss: 3.983853 [ 2560/   30/8300]\n",
            "Funzione di loss: 3.984034 [ 3200/   17/8300]\n",
            "Funzione di loss: 3.985981 [ 3840/   35/8300]\n",
            "Funzione di loss: 3.976512 [ 4480/   15/8300]\n",
            "Funzione di loss: 3.991476 [ 5120/   33/8300]\n",
            "Funzione di loss: 3.954452 [ 5760/   29/8300]\n",
            "Funzione di loss: 3.957228 [ 6400/   15/8300]\n",
            "Funzione di loss: 3.985288 [ 7040/   13/8300]\n",
            "Funzione di loss: 4.002162 [ 7680/    9/8300]\n",
            "Errore test: \n",
            " Accuratezza: 93.8%, Media loss: 3.976377 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#Definiamo la loss function e il metodo di minimizzazione\n",
        "learning_rate = 1e-1\n",
        "momentum = 0.9\n",
        "batch_size = 64\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = momentum)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lists_to_write = ['loss_list_train', 'loss_list_test', 'acc_list_train', 'acc_list_test']\n",
        "data = {listname: globals()[listname] for listname in lists_to_write}\n",
        "import json\n",
        "with open('./data_res_lists.txt', 'w') as file:\n",
        "    json.dump(data, file, indent=2)"
      ],
      "metadata": {
        "id": "AUJVhdGJc_Ur"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}